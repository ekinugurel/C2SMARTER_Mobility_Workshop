{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acdeadd-5a5f-4125-8c0c-1df7254831f3",
   "metadata": {},
   "source": [
    "# Understanding Travel Demand through Passively-generated Mobile Data: a Python-based Mobility Analysis Workshop\n",
    "## C2SMARTER Student Learning Hub Series\n",
    "\n",
    "### March 7th, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c481410",
   "metadata": {},
   "source": [
    "## Ekin UÄŸurel\n",
    "### Ph.D. Candidate, Department of Civil and Environmental Engineering, University of Washington\n",
    "### [ekinugurel.github.io](https://ekinugurel.github.io)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fac42f-fbd6-4acb-90d8-64cbbc480e09",
   "metadata": {},
   "source": [
    "#### We will be utilizing open data created by the GeoDS Lab at UW-Madison: https://github.com/GeoDS/COVID19USFlows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder=\"./mobilityflows\"\n",
    "#for i in range(20):\n",
    "#    url = \"https://raw.githubusercontent.com/GeoDS/COVID19USFlows-WeeklyFlows-Ct2021/master/weekly_flows/ct2ct/2021_01_04/weekly_ct2ct_2021_01_04_\"+str(i)+\".csv\"\n",
    "#    wget.download(url, out='./mobilityflows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all files\n",
    "data_folder=\"./mobilityflows\"\n",
    "flow_all = []\n",
    "for file in os.listdir(data_folder):\n",
    "    if file[-3:] == \"csv\" and 'weekly_ct2ct' in file:\n",
    "        #print(data_folder+\"/\"+file)\n",
    "        flow_df = pd.read_csv(data_folder+\"/\"+file)\n",
    "        flow_all.append(flow_df)\n",
    "flow_all = pd.concat([x for x in flow_all])\n",
    "print(flow_all.shape)\n",
    "flow_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b16258-df05-4d90-aac2-49ceee939bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0c2b7-da75-496f-95a8-ae531c782e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate New York county (36061)\n",
    "ny_county_flows_ct = flow_all[(flow_all['geoid_o'] > 36060999999) & (flow_all['geoid_o'] < 36061999999) & (flow_all['geoid_d'] < 36061999999) & (flow_all['geoid_d'] > 36060999999)]\n",
    "print(ny_county_flows_ct.shape)\n",
    "ny_county_flows_ct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8348882",
   "metadata": {},
   "source": [
    "## Delete Larger Data from Memory\n",
    "Due to memory limitations within Binder (hosted with Kubernetes), we will delete the larger data from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ac714",
   "metadata": {},
   "outputs": [],
   "source": [
    "del flow_all, flow_df, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusdata\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_county_flows_ct[['geoid_o', 'geoid_d']] = ny_county_flows_ct[['geoid_o','geoid_d']].astype(str) # Multiple columns string conversion\n",
    "print(ny_county_flows_ct.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d76ae-fbdc-4a74-824b-1ee472596be0",
   "metadata": {},
   "source": [
    "## Download the Census data for New York county\n",
    "Here we will leverage the 'censusdata' package, which is a Python wrapper for the US Census Bureau API. We will download the Census data for New York county.\n",
    "\n",
    "Below are some helper functions to download the data. Thanks to Eric Gagliano and Professor David Shean for developing and sharing these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae99686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_data(tables, state, county, year=2022):\n",
    "\n",
    "    # Download the data\n",
    "    data = censusdata.download('acs5', year,  # Use 2022 ACS 5-year estimates\n",
    "                               censusdata.censusgeo([('state', state), ('county', county), ('tract', '*'), ('block group', '*')]),\n",
    "                               list(tables.keys()))\n",
    "\n",
    "    # Rename the column\n",
    "    data.rename(columns=tables, inplace=True)\n",
    "\n",
    "    # Extract information from the first column\n",
    "    data['Name'] = data.index.to_series().apply(lambda x: x.name)\n",
    "    data['SummaryLevel'] = data.index.to_series().apply(lambda x: x.sumlevel())\n",
    "    data['State'] = data.index.to_series().apply(lambda x: x.geo[0][1])\n",
    "    data['County'] = data.index.to_series().apply(lambda x: x.geo[1][1])\n",
    "    data['Tract'] = data.index.to_series().apply(lambda x: x.geo[2][1])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data[['Tract','Name']+list(tables.values())].set_index('Tract')\n",
    "    return data\n",
    "\n",
    "def get_census_tract_geom(state_fips, county_fips):\n",
    "\n",
    "    # find state and county fips here: https://www.census.gov/geographies/reference-files/2017/demo/popest/2017-fips.html\n",
    "    \n",
    "    # Download the census tract shapefiles\n",
    "    tracts = gpd.read_file(f'https://www2.census.gov/geo/tiger/TIGER2021/TRACT/tl_2021_{state_fips}_tract.zip')\n",
    "\n",
    "    # set index as tract\n",
    "    tracts = tracts.rename(columns={'TRACTCE':'Tract'}).set_index('Tract')\n",
    "\n",
    "    # Filter to only King County\n",
    "    tracts = tracts[tracts['COUNTYFP'] == county_fips]\n",
    "    tracts = tracts[['geometry']]\n",
    "\n",
    "    return tracts\n",
    "\n",
    "def convert_to_percentages(df, total_population_column='TotalPopulation'):\n",
    "    for column in df.columns:\n",
    "        if column.startswith('Population'):\n",
    "            new_column_name = 'Percent' + column\n",
    "            df[new_column_name] = (df[column] / df[total_population_column]) * 100\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0346441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state and county for New York City\n",
    "state_fips = '36'  # FIPS code for New York\n",
    "county_fips = '061'  # FIPS code for New York County\n",
    "\n",
    "tables = {\n",
    "'B19013_001E': 'MedianIncome',\n",
    "'B01003_001E': 'TotalPopulation',\n",
    "'B01002_001E': 'MedianAge',\n",
    "'B02001_002E': 'PopulationWhiteAlone',\n",
    "'B02001_003E': 'PopulationBlackAlone',\n",
    "'B02001_004E': 'PopulationAmericanIndianAlaskaNativeAlone',\n",
    "'B02001_005E': 'PopulationAsianAlone',\n",
    "'B02001_006E': 'PopulationNativeHawaiianPacificIslanderAlone',\n",
    "'B02001_007E': 'PopulationSomeOtherRaceAlone',\n",
    "'B02001_008E': 'PopulationTwoOrMoreRaces',\n",
    "'B03002_003E': 'PopulationNotHispanicWhiteAlone',\n",
    "'B03003_003E': 'PopulationHispanic',\n",
    "'B25064_001E': 'MedianGrossRent',\n",
    "'B25077_001E': 'MedianHomeValue',\n",
    "'B25035_001E': 'MedianYearStructureBuilt',\n",
    "'B25001_001E': 'TotalHousingUnits',\n",
    "'B25004_001E': 'TotalVacantHousingUnits',\n",
    "'B25003_002E': 'OccupiedHousingUnitsOwnerOccupied',\n",
    "'B25003_003E': 'OccupiedHousingUnitsRenterOccupied',\n",
    "'B08303_002E': 'TravelTimeToWork_lessthan5min',\n",
    "'B08303_003E': 'TravelTimeToWork_5to9min',\n",
    "'B08303_004E': 'TravelTimeToWork_10to14min',\n",
    "'B08303_005E': 'TravelTimeToWork_15to19min',\n",
    "'B08303_006E': 'TravelTimeToWork_20to24min',\n",
    "'B08303_007E': 'TravelTimeToWork_25to29min',\n",
    "'B08303_008E': 'TravelTimeToWork_30to34min',\n",
    "'B08303_009E': 'TravelTimeToWork_35to44min',\n",
    "'B08303_010E': 'TravelTimeToWork_45to59min',\n",
    "'B08303_011E': 'TravelTimeToWork_60to89min',\n",
    "'B08303_012E': 'TravelTimeToWork_90ormoremin',\n",
    "'B08301_002E': 'MeansOfTransportationToWork_CarTruckVan',\n",
    "'B08301_010E': 'MeansOfTransportationToWork_PublicTransportation',\n",
    "'B08301_018E': 'MeansOfTransportationToWork_Bicycle',\n",
    "'B08301_019E': 'MeansOfTransportationToWork_Walked',\n",
    "'B08301_021E': 'MeansOfTransportationToWork_WorkedFromHome',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8600a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "data = censusdata.download('acs5', 2021,  # Use 2021 ACS 5-year estimates\n",
    "                            censusdata.censusgeo([('state', state_fips), ('county', county_fips), ('tract', '*'), ('block group', '*')]),\n",
    "                            list(tables.keys()))\n",
    "\n",
    "census_data = get_census_data(tables, state_fips, county_fips)\n",
    "census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_geom_gdf = get_census_tract_geom(state_fips, county_fips).to_crs('EPSG:4326')\n",
    "tract_geom_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format census data, change dtype of Tract so that it matches census_data\n",
    "census_data = census_data.reset_index()\n",
    "census_data['Tract'] = census_data['Tract'].astype('object')\n",
    "\n",
    "census_data_geoms = census_data.merge(tract_geom_gdf, on='Tract', how='left')\n",
    "census_data_geoms[['Tract', 'Name', 'geometry']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_geoms['geometry'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37767f75",
   "metadata": {},
   "source": [
    "Read more about geometry objects here: https://autogis-site.readthedocs.io/en/latest/lessons/lesson-1/geometry-objects.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to geodataframe\n",
    "census_data_geoms_gdf = gpd.GeoDataFrame(census_data_geoms, crs='EPSG:4326', geometry=census_data_geoms.geometry)\n",
    "\n",
    "# Remove tracts with no population\n",
    "census_data_geoms_gdf = census_data_geoms_gdf[census_data_geoms_gdf.TotalPopulation > 0]\n",
    "\n",
    "# Plot the data\n",
    "f, ax = plt.subplots(1,2,figsize=(12,8))\n",
    "# New York County Median Income\n",
    "king_plot = census_data_geoms_gdf.plot(column='MedianIncome', cmap='inferno', legend=True, ax=ax[0], vmax=200000, vmin=0)\n",
    "ax[0].set_title(\"New York County Median Income per CBG\")\n",
    "\n",
    "# New York County Median Age\n",
    "census_data_geoms_gdf.plot(column='MedianAge', cmap='inferno', legend=True, ax=ax[1], vmin=0, vmax=65)\n",
    "ax[1].set_title(\"New York County Median Age per CBG\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_geoms_gdf['GEOID'] = '36061' + census_data_geoms_gdf['Tract']\n",
    "census_data_geoms_gdf['GEOID'] = census_data_geoms_gdf['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40686c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV in case the federal government shuts down...\n",
    "#census_data_geoms_gdf.to_csv('NY_census_data_geoms_gdf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd85211",
   "metadata": {},
   "source": [
    "## Merging Census data with the OD data\n",
    "We will use 'pd.DataFrame.merge' to merge the Census data with the OD data. You can read about how to use this function more generally here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "In this case, we will do a 'right' merge on the GEOID column. This is equivalent to a SQL right outer join, using only keys from the right DataFrame (census_data_geoms_gdf). We do this to keep all the rows from the census data, even if there is no corresponding row in the OD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf04a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_merged_o = ny_county_flows_ct.merge(census_data_geoms_gdf, left_on='geoid_o', right_on='GEOID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm what we are doing is working as intended. Let's look at the number of unique GEOIDs in each dataset.\n",
    "print(f\"Unique origin GEOIDs in NY County Flows: {ny_county_flows_ct['geoid_o'].nunique()}\")\n",
    "print(f\"Unique destination GEOIDs in NY County Flows: {ny_county_flows_ct['geoid_d'].nunique()}\")\n",
    "print(f\"Unique GEOIDs in NY County Census Data: {census_data_geoms_gdf['GEOID'].nunique()}\")\n",
    "print(f\"Unique GEOIDs in Merged Data: {ny_merged_o['GEOID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3c772",
   "metadata": {},
   "source": [
    "Let's now merge again to get the destination census data in the same tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge again to now get the destination census data\n",
    "ny_merged_od = ny_merged_o.merge(census_data_geoms_gdf, left_on='geoid_d', right_on='GEOID', how='right', suffixes=('_origin', '_destination'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ny_merged has any NA values\n",
    "print(ny_merged_od.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NA values\n",
    "ny_merged = ny_merged_od.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a62b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df378d",
   "metadata": {},
   "source": [
    "## Origin-Destination Matrix\n",
    "To create this matrix, we can use the '.pivot_table()' method in pandas. This method is used to create a spreadsheet-style pivot table as a DataFrame. You can read more about this method here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\n",
    "\n",
    "Some observations: \n",
    "- The diagonal of the matrix (representing trips within a single zone) tends to have the highest values. \n",
    "  - This is expected, as people are more likely to travel within their own zone. \n",
    "- The matrix is NOT symmetric, as the number of trips from zone A to zone B is not necessarily the same as the number of trips from zone B to zone A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'geoid_o' to 'origin' and 'geoid_d' to 'destination'\n",
    "ny_merged = ny_merged.rename(columns={'geoid_o': 'origin', 'geoid_d': 'destination'})\n",
    "ny_merged['flow'] = ny_merged['pop_flows']\n",
    "ny_merged['tile_ID'] = ny_merged['origin']\n",
    "\n",
    "# Convert ny_merged into a Origin-Destination matrix using pivot_table\n",
    "od_matrix = ny_merged.pivot_table(index='origin', columns='destination', values='flow', fill_value=0)\n",
    "od_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(od_matrix, cmap='inferno', vmin=0, vmax=500)\n",
    "plt.colorbar()\n",
    "plt.title('NY County Origin-Destination Matrix (01/04/21 - 01/10/21)')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Origin')\n",
    "plt.savefig('img/NY_OD_Matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f3df0",
   "metadata": {},
   "source": [
    "Census tract map of New York county: https://www2.census.gov/geo/maps/DC2020/PL20/st36_ny/censustract_maps/c36061_new_york/DC20CT_C36061.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aef3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate straight-line distance between origin and destination\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the distance between two points in kilometers using the Haversine formula\"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Calculate distances (using lat_o, lng_o, lat_d, lng_d from ny_merged_od)\n",
    "ny_merged['distance_km'] = haversine_distance(\n",
    "    ny_merged['lat_o'], ny_merged['lng_o'],\n",
    "    ny_merged['lat_d'], ny_merged['lng_d']\n",
    ")\n",
    "\n",
    "# Drop rows where distance is zero\n",
    "ny_merged = ny_merged[ny_merged['distance_km'] > 0]\n",
    "\n",
    "# Rename some columns for clarity\n",
    "ny_merged['flow'] = ny_merged['pop_flows']\n",
    "ny_merged['tile_ID'] = ny_merged['origin']\n",
    "\n",
    "# Create a log-scaled flow value (useful for visualization)\n",
    "ny_merged['log_flow'] = np.log1p(ny_merged['flow'])  # log(1+x) to handle zero flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c642158",
   "metadata": {},
   "source": [
    "## Income-based Mobility Patterns Analysis\n",
    "### Let's calculate median income categories for quantiles.\n",
    "\n",
    "We will create income 'bins' using pd.qcut. You can read more about this function here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_bins_origin = pd.qcut(ny_merged['MedianIncome_origin'], 5, labels=False)  # Split into quintiles\n",
    "ny_merged['income_quintile_origin'] = income_bins_origin + 1  # Make 1-based\n",
    "\n",
    "# Do the same for destination income\n",
    "income_bins_destination = pd.qcut(ny_merged['MedianIncome_destination'], 5, labels=False)\n",
    "ny_merged['income_quintile_destination'] = income_bins_destination + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33248872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create income group descriptions for better readability\n",
    "income_labels = {\n",
    "    1: 'Very Low Income',\n",
    "    2: 'Low Income',\n",
    "    3: 'Middle Income',\n",
    "    4: 'High Income',\n",
    "    5: 'Very High Income'\n",
    "}\n",
    "\n",
    "# Analyze flow patterns by income groups\n",
    "income_flow_matrix = ny_merged.pivot_table(\n",
    "    values='flow',\n",
    "    index='income_quintile_origin',\n",
    "    columns='income_quintile_destination',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Create a normalized version (by row)\n",
    "income_flow_matrix_norm = income_flow_matrix.div(income_flow_matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize income-based flow matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot the raw flow matrix\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(income_flow_matrix,  fmt='.0f', cmap='viridis',\n",
    "            xticklabels=[income_labels[i] for i in range(1, 6)],\n",
    "            yticklabels=[income_labels[i] for i in range(1, 6)])\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.ylabel('Origin Income Group', fontsize=14)\n",
    "# Make tick labels larger\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Plot the normalized flow matrix\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(income_flow_matrix_norm, annot=True, fmt='.2f', cmap='viridis',\n",
    "            xticklabels=[income_labels[i] for i in range(1, 6)],\n",
    "            yticklabels=[income_labels[i] for i in range(1, 6)])\n",
    "plt.xlabel('Destination Income Group', fontsize=14)\n",
    "plt.ylabel('Origin Income Group', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/income_based_flows.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a3b4f",
   "metadata": {},
   "source": [
    "## Spatial Visualization of Flows\n",
    "### We can create interactive maps using the 'folium' package. You can read more about this package here: https://python-visualization.github.io/folium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea5bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flows_on_map(gdf, flows_df, max_flows=1000, min_flow=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize flows on an interactive map\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geodataframe with census tracts\n",
    "    flows_df : DataFrame\n",
    "        DataFrame with flow data (must have origin, destination, flow, lng_o, lat_o, lng_d, lat_d)\n",
    "    max_flows : int\n",
    "        Maximum number of flows to visualize\n",
    "    min_flow : float\n",
    "        Minimum flow value to visualize\n",
    "    save_path : str, optional\n",
    "        Path to save the interactive map HTML file\n",
    "    \"\"\"\n",
    "    # Filter flows to reduce visual clutter\n",
    "    filtered_flows = flows_df[flows_df['flow'] > min_flow].sort_values('flow', ascending=False).head(max_flows)\n",
    "    \n",
    "    # Create map centered on the mean coordinates\n",
    "    center_lat = flows_df[['lat_o', 'lat_d']].values.mean()\n",
    "    center_lng = flows_df[['lng_o', 'lng_d']].values.mean()\n",
    "    \n",
    "    m = folium.Map(location=[center_lat, center_lng], zoom_start=12, tiles='cartodbpositron')\n",
    "    \n",
    "    # Add census tracts\n",
    "    #folium.GeoJson(\n",
    "    #    gdf,\n",
    "    #    style_function=lambda x: {\n",
    "    #        'fillColor': 'transparent',\n",
    "    #        'color': 'black',\n",
    "    #        'weight': 0.5,\n",
    "    #        'fillOpacity': 0.1,\n",
    "    #    }\n",
    "    #).add_to(m)\n",
    "    \n",
    "    # Normalize flow values for line width\n",
    "    max_flow = filtered_flows['flow'].max()\n",
    "    min_flow = filtered_flows['flow'].min()\n",
    "    \n",
    "    # Add flow lines\n",
    "    for _, row in filtered_flows.iterrows():\n",
    "        # Calculate line width based on flow\n",
    "        width = 1 + 5 * ((row['flow'] - min_flow) / (max_flow - min_flow))\n",
    "        \n",
    "        # Determine color based on distance (shorter = more blue, longer = more red)\n",
    "        norm_distance = min(1.0, row['distance_km'] / 10)  # Normalize to 0-1 range (capped at 10km)\n",
    "        color = f'#{int(255 * norm_distance):02x}{0:02x}{int(255 * (1-norm_distance)):02x}'\n",
    "        \n",
    "        # Draw the flow line\n",
    "        folium.PolyLine(\n",
    "            locations=[[row['lat_o'], row['lng_o']], [row['lat_d'], row['lng_d']]],\n",
    "            color=color,\n",
    "            weight=width,\n",
    "            opacity=0.7\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Save map if path is provided\n",
    "    if save_path:\n",
    "        m.save(save_path)\n",
    "        \n",
    "    return m\n",
    "\n",
    "flow_map = visualize_flows_on_map(\n",
    "    census_data_geoms_gdf,\n",
    "    ny_merged,\n",
    "    max_flows=50000,\n",
    "    min_flow=1000,\n",
    "    save_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d523124",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab02cf5",
   "metadata": {},
   "source": [
    "## Analyzing Transportation Preferences by Income\n",
    "### Let's calculate percent of each transportation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ec3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_columns = [\n",
    "    'MeansOfTransportationToWork_CarTruckVan_origin',\n",
    "    'MeansOfTransportationToWork_PublicTransportation_origin',\n",
    "    'MeansOfTransportationToWork_Bicycle_origin',\n",
    "    'MeansOfTransportationToWork_Walked_origin',\n",
    "    'MeansOfTransportationToWork_WorkedFromHome_origin'\n",
    "]\n",
    "\n",
    "# Group by income quintile and calculate mean for each transportation mode\n",
    "transport_by_income = ny_merged.groupby('income_quintile_origin')[transport_columns].mean()\n",
    "\n",
    "# Calculate total commuters for each row\n",
    "transport_by_income['total_commuters'] = transport_by_income.sum(axis=1)\n",
    "\n",
    "# Convert to percentages\n",
    "for col in transport_columns:\n",
    "    transport_by_income[f'{col}_pct'] = transport_by_income[col] / transport_by_income['total_commuters'] * 100\n",
    "    \n",
    "transport_by_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stacked bar chart of transportation modes by income\n",
    "transport_pct_columns = [f'{col}_pct' for col in transport_columns]\n",
    "ax = transport_by_income[transport_pct_columns].plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    colormap='viridis',\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "\n",
    "legend = ['Car/Truck/Van', 'Public Transportation', 'Bicycle', 'Walked', 'Worked from Home']\n",
    "\n",
    "plt.xlabel('Income Quintile',  fontsize=20)\n",
    "plt.ylabel('Percentage of Commuters',  fontsize=20)\n",
    "#plt.title('Means of Transportation by Income Group')\n",
    "plt.xticks(range(5), [income_labels[i] for i in range(1, 6)], rotation=30)\n",
    "plt.legend(legend, loc='upper center', bbox_to_anchor=(1.2, 1), fontsize=16)\n",
    "plt.grid(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/transportation_by_income.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0e756",
   "metadata": {},
   "source": [
    "## Flow Distance Analysis by Income Group\n",
    "### Let's calculate the average travel distance by income group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_by_income = ny_merged.groupby('income_quintile_origin')['distance_km'].agg(['mean', 'median', 'count'])\n",
    "distance_by_income.columns = ['Mean Distance (km)', 'Median Distance (km)', 'Number of Flows']\n",
    "distance_by_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize travel distance distribution by income\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='income_quintile_origin', y='distance_km', data=ny_merged, palette='viridis')\n",
    "plt.xlabel('Income Quintile',  fontsize=20)\n",
    "plt.ylabel('Travel Distance (km)', fontsize=20)\n",
    "#plt.title('Distribution of Travel Distances by Income Group', fontsize=20)\n",
    "plt.xticks(range(5), [income_labels[i+1] for i in range(5)])\n",
    "#plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# Make axes titles + labels larger\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.savefig('img/travel_distance_by_income.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c4046",
   "metadata": {},
   "source": [
    "## Age-based Mobility Analysis\n",
    "### Let's create age group categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 25, 35, 45, 55, 65, 100]\n",
    "age_labels = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "ny_merged['age_group'] = pd.cut(ny_merged['MedianAge_origin'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Calculate mean distance and flow by age group\n",
    "age_mobility = ny_merged.groupby('age_group').agg({\n",
    "    'distance_km': ['mean', 'median'],\n",
    "    'flow': ['mean', 'sum'],\n",
    "    'TotalPopulation_origin': 'sum'\n",
    "})\n",
    "\n",
    "age_mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cc59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Mean distance by age group\n",
    "axes[0].bar(age_mobility.index, age_mobility[('distance_km', 'mean')], color='skyblue')\n",
    "axes[0].set_xlabel('Age Group', fontsize=20)\n",
    "axes[0].set_ylabel('Mean Travel Distance (km)', fontsize=20)\n",
    "#axes[0].set_title('Average Travel Distance by Age Group')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "# Total flow by age group\n",
    "axes[1].bar(age_mobility.index, age_mobility[('flow', 'sum')], color='lightsalmon')\n",
    "axes[1].set_xlabel('Age Group', fontsize=20)\n",
    "axes[1].set_ylabel('Total Flow Volume', fontsize=20)\n",
    "#axes[1].set_title('Total Mobility Flow by Age Group')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/age_based_mobility.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf03ec3",
   "metadata": {},
   "source": [
    "## Inbound vs. Outbound Flow Analysis\n",
    "### Let's calculate total inflows and outflows for each tract\n",
    "This is likely a good indicator of the economic activity in the area (i.e., number of jobs, services, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31308ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_flows = pd.DataFrame({\n",
    "    'tract': census_data_geoms_gdf['GEOID'].unique()\n",
    "})\n",
    "\n",
    "# Calculate total outflows for each tract\n",
    "outflows = ny_merged.groupby('origin')['flow'].sum().reset_index()\n",
    "outflows.columns = ['tract', 'total_outflow']\n",
    "\n",
    "# Calculate total inflows for each tract\n",
    "inflows = ny_merged.groupby('destination')['flow'].sum().reset_index()\n",
    "inflows.columns = ['tract', 'total_inflow']\n",
    "\n",
    "# Merge inflows and outflows\n",
    "tract_flows = tract_flows.merge(outflows, on='tract', how='left')\n",
    "tract_flows = tract_flows.merge(inflows, on='tract', how='left')\n",
    "\n",
    "# Fill NAs with 0\n",
    "tract_flows = tract_flows.fillna(0)\n",
    "\n",
    "tract_flows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate net flow (inflow - outflow)\n",
    "tract_flows['net_flow'] = tract_flows['total_inflow'] - tract_flows['total_outflow']\n",
    "tract_flows['flow_ratio'] = tract_flows['total_inflow'] / tract_flows['total_outflow'].replace(0, np.nan)\n",
    "tract_flows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with census data\n",
    "tract_analysis = tract_flows.merge(\n",
    "    census_data_geoms_gdf[['GEOID', 'MedianIncome', 'TotalPopulation', 'geometry']],\n",
    "    left_on='tract',\n",
    "    right_on='GEOID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Create a GeoDataFrame for mapping\n",
    "tract_analysis_gdf = gpd.GeoDataFrame(tract_analysis, geometry='geometry')\n",
    "tract_analysis_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be887045",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 13))\n",
    "\n",
    "# Create colormap and normalize\n",
    "cmap = plt.cm.RdBu\n",
    "vmin, vmax = -tract_analysis_gdf['net_flow'].abs().max() / 2, tract_analysis_gdf['net_flow'].abs().max() / 2\n",
    "\n",
    "# Plot net flow\n",
    "tract_analysis_gdf.plot(\n",
    "    column='net_flow',\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    legend=True,\n",
    "    legend_kwds={'label': 'Net Flow (Inflow - Outflow)'},\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3\n",
    ")\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Net Mobility Flow by Census Tract', fontsize=15)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/net_flow_map.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71cc3b4",
   "metadata": {},
   "source": [
    "## Correlation Analysis: Socioeconomic Factors and Mobility\n",
    "### Let's merge inflow/outflow with census variables to calculate correlation\n",
    "\n",
    "This time we will use an 'inner' join, combining rows that have matching values in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_census = tract_analysis.merge(\n",
    "    census_data_geoms_gdf[[\n",
    "        'GEOID', 'MedianIncome', 'TotalPopulation', 'MedianAge',\n",
    "        'PopulationWhiteAlone', 'PopulationBlackAlone', \n",
    "        'MeansOfTransportationToWork_PublicTransportation',\n",
    "        'MeansOfTransportationToWork_CarTruckVan',\n",
    "        'MeansOfTransportationToWork_Walked'\n",
    "    ]],\n",
    "    left_on='GEOID',\n",
    "    right_on='GEOID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "flow_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportion of transport modes\n",
    "flow_census['pct_public_transit'] = (\n",
    "    flow_census['MeansOfTransportationToWork_PublicTransportation'] / \n",
    "    (flow_census['MeansOfTransportationToWork_PublicTransportation'] + \n",
    "     flow_census['MeansOfTransportationToWork_CarTruckVan'] +\n",
    "     flow_census['MeansOfTransportationToWork_Walked'])\n",
    ") * 100\n",
    "\n",
    "# Select variables for correlation analysis\n",
    "correlation_vars = [\n",
    "    'total_inflow', 'total_outflow', 'net_flow',\n",
    "    'MedianIncome_x', 'TotalPopulation_x', 'MedianAge', 'pct_public_transit'\n",
    "]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = flow_census[correlation_vars].corr()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd60a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=.3,\n",
    "    vmin=-.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    annot=True,\n",
    "    fmt=\".2f\"\n",
    ")\n",
    "plt.title('Correlation Between Socioeconomic Factors and Mobility Flows')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/correlation_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da964a",
   "metadata": {},
   "source": [
    "## Exploring the Gravity Model Assumptions\n",
    "### The gravity model assumes that flow is proportional to masses (populations) and inversely proportional to distance\n",
    "$$\n",
    "T_{ij} = K \\cdot \\frac{m_i^{\\alpha} m_j^{\\beta}}{d_{ij}^{\\gamma}}\n",
    "$$\n",
    "where $T_{ij}$ is the flow from origin $i$ to destination $j$, $m_i$ and $m_j$ are the populations of the origin and destination, $d_{ij}$ is the distance between the origin and destination, and $K$, $\\alpha$, $\\beta$, and $\\gamma$ are parameters to be estimated.\n",
    "\n",
    "__Key Assumptions__:\n",
    "1. Mass Attraction: The number of trips between two locations is proportional to the product of their populations.\n",
    "2. Distance Decay: The number of trips between two locations is inversely proportional to the distance between them.\n",
    "3. Independence: The number of trips between two locations is independent of the presence of other locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7afe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the gravity model term\n",
    "ny_merged['gravity_term'] = (ny_merged['TotalPopulation_origin'] * ny_merged['TotalPopulation_destination']) / (ny_merged['distance_km']**2)\n",
    "ny_merged['log_gravity_term'] = np.log1p(ny_merged['gravity_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a066da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Flow vs. Distance\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(ny_merged['distance_km'], ny_merged['flow'], alpha=0.4, s=10)\n",
    "# Fit a linear regression line\n",
    "m, b = np.polyfit(ny_merged['distance_km'], ny_merged['flow'], 1)\n",
    "plt.plot(ny_merged['distance_km'], m * ny_merged['distance_km'] + b, color='red')\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Flow Volume')\n",
    "plt.title('Flow vs. Distance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Flow vs. Origin Population\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(ny_merged['TotalPopulation_origin'], ny_merged['flow'], alpha=0.4, s=10)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Origin Population')\n",
    "plt.ylabel('Flow Volume')\n",
    "plt.title('Flow vs. Origin Population')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Flow vs. Destination Population\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(ny_merged['TotalPopulation_destination'], ny_merged['flow'], alpha=0.4, s=10)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Destination Population')\n",
    "plt.ylabel('Flow Volume')\n",
    "plt.title('Flow vs. Destination Population')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Flow vs. Gravity Model Term\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(ny_merged['gravity_term'], ny_merged['flow'], alpha=0.4, s=10)\n",
    "m, b = np.polyfit(ny_merged['gravity_term'], ny_merged['flow'], 1)\n",
    "plt.plot(ny_merged['gravity_term'], m * ny_merged['gravity_term'] + b, color='red')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Gravity Model Term (Pop_o * Pop_d / DistanceÂ²)')\n",
    "plt.ylabel('Flow Volume')\n",
    "plt.title('Flow vs. Gravity Term')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('gravity_model_relationships.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation between flow and gravity model term\n",
    "flow_gravity_corr, p_value = pearsonr(ny_merged['log_flow'], ny_merged['log_gravity_term'])\n",
    "print(f\"Correlation between log(flow) and log(gravity term): {flow_gravity_corr:.4f}, p-value: {p_value:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64013f74",
   "metadata": {},
   "source": [
    "## Gravity Model Fit Test\n",
    "### Let's now create a simple gravity model and test how well it fits the data\n",
    "\n",
    "In this case, we won't use MLE to find optimal parameters but simply solve this linearly.\n",
    "$$\n",
    "\\log(T_{ij}) = \\alpha + \\beta_1 \\log(m_i) + \\beta_2 \\log(m_j) - \\beta_3 \\log(d_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca410b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression\n",
    "model_data = ny_merged.copy()\n",
    "model_data['log_flow'] = np.log1p(model_data['flow'])\n",
    "model_data['log_pop_origin'] = np.log1p(model_data['TotalPopulation_origin'])\n",
    "model_data['log_pop_dest'] = np.log1p(model_data['TotalPopulation_destination'])\n",
    "model_data['log_distance'] = np.log1p(model_data['distance_km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = model_data[['log_pop_origin', 'log_pop_dest', 'log_distance']]\n",
    "X = sm.add_constant(X)\n",
    "y = model_data['log_flow']\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['predicted_log_flow'] = model.predict(X)\n",
    "model_data['predicted_flow'] = np.expm1(model_data['predicted_log_flow'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(model_data['flow'], model_data['predicted_flow'], alpha=0.4, s=10)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Observed Flow', fontsize=14)\n",
    "plt.ylabel('Predicted Flow (Gravity Model)', fontsize=14)\n",
    "#plt.plot([1, model_data['flow'].max()], [1, model_data['flow'].max()], 'r--', alpha=0.7)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('gravity_model_performance.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RÂ² for the model\n",
    "r_squared = model.rsquared\n",
    "print(f\"Gravity Model RÂ²: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3e496",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def common_part_of_commuters(observed, predicted):\n",
    "    \"\"\"\n",
    "    Calculate Common Part of Commuters (CPC) metric\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    observed : array-like\n",
    "        Observed flows\n",
    "    predicted : array-like\n",
    "        Predicted flows\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        CPC value (0-1)\n",
    "    \"\"\"\n",
    "    observed = np.array(observed)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # Scale predicted flows to match total observed\n",
    "    scaling_factor = np.sum(observed) / np.sum(predicted)\n",
    "    predicted_scaled = predicted * scaling_factor\n",
    "    \n",
    "    # Calculate CPC\n",
    "    cpc = np.sum(np.minimum(observed, predicted_scaled)) / np.sum(observed)\n",
    "    \n",
    "    return cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85616afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract arrays\n",
    "observed = model_data['flow'].values\n",
    "gravity_pred = model_data['predicted_flow'].values\n",
    "\n",
    "# Initialize results dictionary\n",
    "metrics = {\n",
    "    'model': ['Gravity Model'],\n",
    "    'RMSE': [0],\n",
    "    'RMSE (log)': [0],\n",
    "    'CPC': [0],\n",
    "}\n",
    "\n",
    "# Calculate metrics for gravity model\n",
    "metrics['RMSE'][0] = np.sqrt(mean_squared_error(observed, gravity_pred))\n",
    "\n",
    "# Log-transformed RMSE - add small constant to handle zeros\n",
    "log_observed = np.log1p(observed)\n",
    "log_gravity_pred = np.log1p(gravity_pred)\n",
    "\n",
    "metrics['RMSE (log)'][0] = np.sqrt(mean_squared_error(log_observed, log_gravity_pred))\n",
    "metrics['CPC'][0] = common_part_of_commuters(observed, gravity_pred)\n",
    "\n",
    "# Create DataFrame for results\n",
    "results_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcefce",
   "metadata": {},
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In NYMerged, convert origin, destination, and tile_ID to int64\n",
    "ny_merged['origin'] = ny_merged['origin'].astype(int)\n",
    "ny_merged['destination'] = ny_merged['destination'].astype(int)\n",
    "ny_merged['tile_ID'] = ny_merged['tile_ID'].astype(int)\n",
    "\n",
    "census_data_geoms_gdf['GEOID'] = census_data_geoms_gdf['GEOID'].astype(int)\n",
    "\n",
    "# Check if all entries in 'origin' can be found in census_data_gdf['GEOID']\n",
    "dest = set(ny_merged['destination']).difference(set(census_data_geoms_gdf['GEOID']))\n",
    "\n",
    "# Drop all rows in ny_merged where destination is in dest\n",
    "ny_merged = ny_merged[~ny_merged['destination'].isin(dest)]\n",
    "\n",
    "#fdf = skmob.FlowDataFrame(ny_merged, \n",
    "#                          tessellation=census_data_geoms_gdf,\n",
    "#                          tile_id = 'GEOID',\n",
    "#)\n",
    "\n",
    "# compute the total outflows from each location of the tessellation (excluding self loops)\n",
    "#tot_outflows = fdf[fdf['origin'] != fdf['destination']].groupby(by='origin', axis=0)[['flow']].sum().fillna(0)\n",
    "#tessellation = tessellation.merge(tot_outflows, left_on='tile_ID', right_on='origin').rename(columns={'flow': 'tot_outflow'})\n",
    "\n",
    "# load a spatial tessellation\n",
    "url_tess = skmob.utils.constants.NY_COUNTIES_2011\n",
    "tessellation = gpd.read_file(url_tess).rename(columns={'tile_id': 'tile_ID'})\n",
    "\n",
    "# load real flows into a FlowDataFrame\n",
    "fdf_ny_state = skmob.FlowDataFrame.from_file(skmob.utils.constants.NY_FLOWS_2011,\n",
    "\t\t\t\ttessellation=tessellation,\n",
    "\t\t\t\ttile_id='tile_ID',\n",
    "\t\t\t\tsep=\",\")\n",
    "\n",
    "fdf_ny_state.plot_flows(tiles='openstreetmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ec0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skmob.models.gravity import Gravity\n",
    "\n",
    "# # instantiate a singly constrained Gravity model\n",
    "# gravity_singly = Gravity(gravity_type='singly cons/tetrained')\n",
    "# print(gravity_singly)\n",
    "\n",
    "# # start the generation of the synthetic flows\n",
    "# np.random.seed(0)\n",
    "# synth_fdf = gravity_singly.generate(tessellation,\n",
    "# \t\t\t\t   tile_id_column='tile_ID',\n",
    "# \t\t\t\t   tot_outflows_column='tot_outflow',\n",
    "# \t\t\t\t   relevance_column= 'population',\n",
    "# \t\t\t\t   out_format='flows')\n",
    "# # print a portion of the synthetic flows\n",
    "# print(synth_fdf.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
